{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "In this notebook section, we will import the libraries needed to run this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\usuario\\documents\\github\\activity_session8\\venv310\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\usuario\\documents\\github\\activity_session8\\venv310\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\usuario\\documents\\github\\activity_session8\\venv310\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\usuario\\documents\\github\\activity_session8\\venv310\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\usuario\\documents\\github\\activity_session8\\venv310\\lib\\site-packages (from pandas) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\usuario\\documents\\github\\activity_session8\\venv310\\lib\\site-packages (from scikit-learn) (1.11.2)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\usuario\\documents\\github\\activity_session8\\venv310\\lib\\site-packages (from scikit-learn) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\usuario\\documents\\github\\activity_session8\\venv310\\lib\\site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\usuario\\documents\\github\\activity_session8\\venv310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants\n",
    "\n",
    "In this section all constants are defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['pclass', 'age', 'sibsp', 'parch', 'fare']\n",
    "categorical_features = ['sex', 'embarked', 'title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Transformers\n",
    "\n",
    "Define custom transformers in this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        #print(self.attribute_names)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names]\n",
    "\n",
    "class MostFrequentImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X],\n",
    "                                        index=X.columns)\n",
    "        #print(self.most_frequent_)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        for col in X.columns:\n",
    "            X[col] = X[col].fillna(self.most_frequent_[col])\n",
    "        return X\n",
    "\n",
    "class StandardScalerTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.features = X.columns\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        standard_scaler = StandardScaler()\n",
    "        X = X.copy()\n",
    "        X_transformed = pd.DataFrame(standard_scaler.fit_transform(X[self.features]), columns = self.features)\n",
    "        return X_transformed\n",
    "\n",
    "#df_feat_selector = DataFrameSelector(numeric_features)\n",
    "#df_feat_selector.fit(titanic_data)\n",
    "#data_pipe1 = df_feat_selector.transform(titanic_data)\n",
    "#data_pipe1.info()\n",
    "\n",
    "#mostfrequent_imputer = MostFrequentImputer()\n",
    "#mostfrequent_imputer.fit(data_pipe1)\n",
    "#data_pipe2 = mostfrequent_imputer.transform(data_pipe1)\n",
    "#data_pipe2.info()\n",
    "\n",
    "#standardscaler_transformer = StandardScalerTransformer()\n",
    "#standardscaler_transformer.fit(data_pipe2)\n",
    "#data_pipe3 = standardscaler_transformer.transform(data_pipe2)\n",
    "#data_pipe3\n",
    "\n",
    "\n",
    "class OneHotEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variables=None):\n",
    "        self.variables = [variables] if not isinstance(variables, list) else variables\n",
    "        self.X = pd.DataFrame()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.X = X\n",
    "        self.dummies = pd.get_dummies(X[self.variables], drop_first=True).columns\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        self.X = X.copy()\n",
    "        self.X = pd.concat([self.X, pd.get_dummies(self.X[self.variables], drop_first=True)], axis=1)\n",
    "        # X.drop([self.variables], axis=1)\n",
    "        #print(X)\n",
    "\n",
    "        # Adding missing dummies, if any\n",
    "        # missing_dummies = [var for var in self.dummies if var not in X.columns]\n",
    "        # if len(missing_dummies) != 0:\n",
    "        #    for col in missing_dummies:\n",
    "        #        X[col] = 0\n",
    "        return self.X\n",
    "    \n",
    "    def droping(self):\n",
    "        self.X.drop([self.variables], axis = 1)\n",
    "        return self.X\n",
    "\n",
    "\n",
    "#print(categorical_features)\n",
    "#one_encoder = OneHotEncoder(variables=categorical_features)\n",
    "#one_encoder.fit(titanic_data)\n",
    "#aux = one_encoder.transform(titanic_data)\n",
    "#aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "titanic_data = pd.read_csv('raw-data.csv')\n",
    "# print(titanic_data.head())\n",
    "# print()\n",
    "# titanic_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(numeric_features)),\n",
    "    ('imputer', MostFrequentImputer()),\n",
    "    ('scaler', StandardScalerTransformer())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(categorical_features)),\n",
    "    ('imputer', MostFrequentImputer()),\n",
    "    ('encoder', OneHotEncoder(categorical_features))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessor = Columntransformer(\n",
    "preprocessor = Pipeline([\n",
    "    #transformers=[\n",
    "        ('numeric', numeric_pipeline, numeric_features),\n",
    "        ('categorical', categorical_pipeline, categorical_features)\n",
    "        #('categorical_2', categorical_pipeline.named_steps['encoder'].droping())\n",
    "    #],\n",
    "    #remainder='passthrough'  # Allows to preserve remaining columns in the output\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVC_Classifier():\n",
    "    def __init__(self):\n",
    "        self.svc_model = SVC(gamma = 'auto')\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self.svc_model.fit(X = X, y = y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.svc_model.predict(X = X)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    # TODO: Add here the preprocessor and a SVC trainer\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', SVC_Classifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features - Target defined.\n",
      "Train - Test splitted.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[135], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTrain - Test splitted.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[39m# Fit the pipeline on the training data\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m pipeline\u001b[39m.\u001b[39;49mnamed_steps[\u001b[39m'\u001b[39;49m\u001b[39mpreprocessor\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     12\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPipeline fitted.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\usuario\\Documents\\GitHub\\activity_session8\\venv310\\lib\\site-packages\\sklearn\\pipeline.py:377\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params):\n\u001b[0;32m    352\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \n\u001b[0;32m    354\u001b[0m \u001b[39m    Fit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[39m        Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 377\u001b[0m     fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    378\u001b[0m     Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_steps)\n\u001b[0;32m    379\u001b[0m     \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n",
      "File \u001b[1;32mc:\\Users\\usuario\\Documents\\GitHub\\activity_session8\\venv310\\lib\\site-packages\\sklearn\\pipeline.py:297\u001b[0m, in \u001b[0;36mPipeline._check_fit_params\u001b[1;34m(self, **fit_params)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_fit_params\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params):\n\u001b[1;32m--> 297\u001b[0m     fit_params_steps \u001b[39m=\u001b[39m {name: {} \u001b[39mfor\u001b[39;00m name, step \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps \u001b[39mif\u001b[39;00m step \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m}\n\u001b[0;32m    298\u001b[0m     \u001b[39mfor\u001b[39;00m pname, pval \u001b[39min\u001b[39;00m fit_params\u001b[39m.\u001b[39mitems():\n\u001b[0;32m    299\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m__\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pname:\n",
      "File \u001b[1;32mc:\\Users\\usuario\\Documents\\GitHub\\activity_session8\\venv310\\lib\\site-packages\\sklearn\\pipeline.py:297\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_fit_params\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params):\n\u001b[1;32m--> 297\u001b[0m     fit_params_steps \u001b[39m=\u001b[39m {name: {} \u001b[39mfor\u001b[39;00m name, step \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps \u001b[39mif\u001b[39;00m step \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m}\n\u001b[0;32m    298\u001b[0m     \u001b[39mfor\u001b[39;00m pname, pval \u001b[39min\u001b[39;00m fit_params\u001b[39m.\u001b[39mitems():\n\u001b[0;32m    299\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m__\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pname:\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# Separate features (X) and target (y)\n",
    "X = titanic_data.drop(['survived', 'cabin'], axis=1)  # Exclude 'cabin' column\n",
    "y = titanic_data['survived']\n",
    "print(\"Features - Target defined.\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Train - Test splitted.\")\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline.named_steps['preprocessor'].fit(X_train, y_train)\n",
    "print(\"Pipeline fitted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ColumnTransformer.transform() got an unexpected keyword argument 'flag_drop'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Transform the training and testing data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_train_transformed \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39;49mnamed_steps[\u001b[39m'\u001b[39;49m\u001b[39mpreprocessor\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mtransform(X_train, flag_drop \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      3\u001b[0m X_test_transformed \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39mnamed_steps[\u001b[39m'\u001b[39m\u001b[39mpreprocessor\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mtransform(X_test, flag_drop \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTrain - Test datasets transformed.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: ColumnTransformer.transform() got an unexpected keyword argument 'flag_drop'"
     ]
    }
   ],
   "source": [
    "# Transform the training and testing data\n",
    "X_train_transformed = pipeline.named_steps['preprocessor'].transform(X_train, flag_drop = True)\n",
    "X_test_transformed = pipeline.named_steps['preprocessor'].transform(X_test, flag_drop = True)\n",
    "print(\"Train - Test datasets transformed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.840359</td>\n",
       "      <td>-0.88269</td>\n",
       "      <td>-0.495964</td>\n",
       "      <td>-0.442432</td>\n",
       "      <td>-0.495437</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.355097</td>\n",
       "      <td>0.58346</td>\n",
       "      <td>-0.495964</td>\n",
       "      <td>-0.442432</td>\n",
       "      <td>-0.445125</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.550554</td>\n",
       "      <td>-0.805524</td>\n",
       "      <td>-0.495964</td>\n",
       "      <td>1.795376</td>\n",
       "      <td>0.89083</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.550554</td>\n",
       "      <td>1.432284</td>\n",
       "      <td>0.456833</td>\n",
       "      <td>-0.442432</td>\n",
       "      <td>3.747726</td>\n",
       "      <td>male</td>\n",
       "      <td>C</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.550554</td>\n",
       "      <td>-0.342529</td>\n",
       "      <td>-0.495964</td>\n",
       "      <td>-0.442432</td>\n",
       "      <td>0.171172</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>0.840359</td>\n",
       "      <td>-0.342529</td>\n",
       "      <td>-0.495964</td>\n",
       "      <td>-0.442432</td>\n",
       "      <td>-0.500588</td>\n",
       "      <td>female</td>\n",
       "      <td>Q</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>0.840359</td>\n",
       "      <td>-0.805524</td>\n",
       "      <td>-0.495964</td>\n",
       "      <td>-0.442432</td>\n",
       "      <td>-0.497771</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>0.840359</td>\n",
       "      <td>0.004717</td>\n",
       "      <td>-0.495964</td>\n",
       "      <td>-0.442432</td>\n",
       "      <td>-0.336935</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>0.840359</td>\n",
       "      <td>-0.188198</td>\n",
       "      <td>-0.495964</td>\n",
       "      <td>-0.442432</td>\n",
       "      <td>-0.494873</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>0.840359</td>\n",
       "      <td>-0.033866</td>\n",
       "      <td>-0.495964</td>\n",
       "      <td>-0.442432</td>\n",
       "      <td>-0.495437</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1047 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4       5  6      7  8   \\\n",
       "0     0.840359  -0.88269 -0.495964 -0.442432 -0.495437    male  S     Mr  1   \n",
       "1    -0.355097   0.58346 -0.495964 -0.442432 -0.445125    male  S     Mr  1   \n",
       "2    -1.550554 -0.805524 -0.495964  1.795376   0.89083  female  S   Miss  0   \n",
       "3    -1.550554  1.432284  0.456833 -0.442432  3.747726    male  C  Other  1   \n",
       "4    -1.550554 -0.342529 -0.495964 -0.442432  0.171172    male  S     Mr  1   \n",
       "...        ...       ...       ...       ...       ...     ... ..    ... ..   \n",
       "1042  0.840359 -0.342529 -0.495964 -0.442432 -0.500588  female  Q   Miss  0   \n",
       "1043  0.840359 -0.805524 -0.495964 -0.442432 -0.497771  female  S   Miss  0   \n",
       "1044  0.840359  0.004717 -0.495964 -0.442432 -0.336935    male  S     Mr  1   \n",
       "1045  0.840359 -0.188198 -0.495964 -0.442432 -0.494873  female  S   Miss  0   \n",
       "1046  0.840359 -0.033866 -0.495964 -0.442432 -0.495437  female  S   Miss  0   \n",
       "\n",
       "     9  10 11 12 13 14  \n",
       "0     0  1  0  1  0  0  \n",
       "1     0  1  0  1  0  0  \n",
       "2     0  1  1  0  0  0  \n",
       "3     0  0  0  0  0  1  \n",
       "4     0  1  0  1  0  0  \n",
       "...  .. .. .. .. .. ..  \n",
       "1042  1  0  1  0  0  0  \n",
       "1043  0  1  1  0  0  0  \n",
       "1044  0  1  0  1  0  0  \n",
       "1045  0  1  1  0  0  0  \n",
       "1046  0  1  1  0  0  0  \n",
       "\n",
       "[1047 rows x 15 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'male'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Use the trained classifier to make predictions\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m pipeline\u001b[39m.\u001b[39;49mnamed_steps[\u001b[39m'\u001b[39;49m\u001b[39mclassifier\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mfit(X_train_transformed, y_train)\n\u001b[0;32m      3\u001b[0m y_pred \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39mnamed_steps[\u001b[39m'\u001b[39m\u001b[39mclassifier\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mpredict(X_test_transformed)\n\u001b[0;32m      5\u001b[0m \u001b[39m# Comparing y_pred with y_test to evaluate the predictions\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[40], line 6\u001b[0m, in \u001b[0;36mSVC_Classifier.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y):\n\u001b[1;32m----> 6\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msvc_model\u001b[39m.\u001b[39;49mfit(X \u001b[39m=\u001b[39;49m X, y \u001b[39m=\u001b[39;49m y)\n",
      "File \u001b[1;32mc:\\Users\\usuario\\Documents\\GitHub\\activity_session8\\venv310\\lib\\site-packages\\sklearn\\svm\\_base.py:173\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    171\u001b[0m     check_consistent_length(X, y)\n\u001b[0;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 173\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    174\u001b[0m         X,\n\u001b[0;32m    175\u001b[0m         y,\n\u001b[0;32m    176\u001b[0m         dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat64,\n\u001b[0;32m    177\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    178\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    179\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    180\u001b[0m     )\n\u001b[0;32m    182\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_targets(y)\n\u001b[0;32m    184\u001b[0m sample_weight \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(\n\u001b[0;32m    185\u001b[0m     [] \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m sample_weight, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64\n\u001b[0;32m    186\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\usuario\\Documents\\GitHub\\activity_session8\\venv310\\lib\\site-packages\\sklearn\\base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    594\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    595\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 596\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\usuario\\Documents\\GitHub\\activity_session8\\venv310\\lib\\site-packages\\sklearn\\utils\\validation.py:1070\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1065\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1066\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1067\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1068\u001b[0m     )\n\u001b[1;32m-> 1070\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1071\u001b[0m     X,\n\u001b[0;32m   1072\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m   1073\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m   1074\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1075\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1076\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1077\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m   1078\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m   1079\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m   1080\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m   1081\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m   1082\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1083\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1084\u001b[0m )\n\u001b[0;32m   1086\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1088\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\usuario\\Documents\\GitHub\\activity_session8\\venv310\\lib\\site-packages\\sklearn\\utils\\validation.py:852\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    850\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    851\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 852\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    853\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    854\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    855\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    856\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'male'"
     ]
    }
   ],
   "source": [
    "# Use the trained classifier to make predictions\n",
    "pipeline.named_steps['classifier'].fit(X_train_transformed, y_train)\n",
    "y_pred = pipeline.named_steps['classifier'].predict(X_test_transformed)\n",
    "\n",
    "# Comparing y_pred with y_test to evaluate the predictions\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
